---
title: "Stats 506, F20, Midterm Project Group 1"
author:
  - Hongfan Chen, chenhf@umich.edu
  - Rithu Uppalapati, rurithu@umich.edu
  - Zhihao Xu, xuzhihao@umich.edu
  - Yawen Hu, yawenhu@umich.edu
date: "`r format.Date(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document:
    theme: united
    highlight: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, echo = TRUE)
library(reticulate)
library(tidyverse)
library(Statamarkdown)
use_python("/opt/anaconda3/bin/python")
```

## About

### Research Question
A propensity score is the **conditional probability** that a subject receives "treatment" given the subject’s observed covariates. When estimating treatment effects on a binary outcome, it may happen that the treatments are not randomly assigned to subjects, which is somewhat often the case in observational studies. Propensity scoring aims to mimic what happens in randomized controlled trials by balancing observed covariates between subjects in control and treatment groups.

The purpose of this tutorial is to introduce how to perform propensity score analyses. In the following sections we will use the data from the National Health and Nutrition Examination Survey ([NHANES](https://www.cdc.gov/nchs/nhanes/index.htm)). We will use the propensity score as a tool to figure out the following question:

> Whether or not adult patients with diabetes have higher risk for heart attack (myocardial infarction) in the United States?

Here’s are the main reasons why we choose this method: 

- This dataset is based on observational data but not experimental and thus has selection bias.
- There are many confounding variables, such as age, body mass index (BMI), year of smoking etc. Also, among other variables, like race or income that seem to be irrelevant with this question may also have the potential to impact our outcome and be confounding variables.


### Data Description

From the [NHANES](https://www.cdc.gov/nchs/nhanes/index.htm) dataset, we choose the following variable as the predictors, outcome and treatment.

Outcome: `heart_attack`  
Treatment: `diabetes`  

Predictors:   

|  Variable               | Description                                         |
| ----------------------- | ----------------------------------------------------|
| `relative_heart_attack` | Relatives have heart attack or not                  |
| `gender`                | Gender of the participant                           |
| `age`                   | Age of the participant                              |
| `race`                  | Race of the participant                             |
| `edu`                   | Education Level                                     | 
| `annual_income`         | Annual Income                                       | 
| `bmi`                   | Body Mass Index                                     |
| `smoke_life`            | Smoked at least 100 cigarettes in life or not       |
| `year_smoke`            | Year of smoke                                       |
| `phy_vigorous`          | Doing vigorous work activity or not                 | 
| `phy_moderate`          | Doing moderate work activity or not                 |
| `blood_press`           | Being told high blood pressure                      | 
| `blood_press2`          | Being told high blood pressure 2+ more times or not |
| `year_hyper`            | Year of hypertension                                | 
| `hyper_med`             | Taking hypertension medicine or not                 |
| `hbp_med`               | Taking HBP medicine or not                          | 
| `high_chol`             | Being told high cholesterol level or not            |
| `meadial_access`        | Being able to have medical access or nor            |
| `cover_hc`              | Covered by health care or not                       |
| `health_diet`           | Having a health diet or not                         |

**Note:** For all the binary variable here with value 1 and 0, 1 = Yes and 0 = No


## Tutorial Procedure
#### 1. Create Propensity Score
Just the same as doing a randomized controlled trial, we would want our treatment and control groups to have variables which have similar point estimates, such as roughly same mean age or mean BMI. Then Logistic Regression can be introduced to develop propensity scores, since it can represent the conditional probability that a patient receives the treatment given the observed covariates.

$$
p(x) = P(T=1|X_1, X_2, \ldots, X_n)
$$
Therefore, we create a logistic model in which we take treatment, namely diabetes, as our response, and the other variables (except heart_attack and weights) as our predictors. Then each observation is assigned with a probability on which we can perform our matching.  

Note that we are not overly focusing on how well our model predicts whether a patient receives treatment or not. Here, what is more important is that we include all predictor variables in the model that are correlated or may be correlated with our outcome. So based on this we can do our best to eliminate the bias caused by the pre-treatment characteristics of the dataset.

#### 2. Propensity Score Matching

Here we use the propensity score to create 1-1 mapping between treatment and control groups. We also identify a caliper, which is a defined width based on a proportion of the standard deviation of the logit of the propensity score. Each observation from the treatment group is matched to the nearest observation in the control group that has not yet been matched by propensity score. The observations must have propensity scores that are within the caliper distance of each other. Here we choose 0.2*standard deviation as caliper distance.

#### 3. Compare the Matched Control Group with the Original Control Group

Here we first compute the frequency table and the proportion of having heart attack for both the matched control group and the original control group. We can further use T-test to figure out whether the difference between the control group and the treatment group is statistically significant or not.

#### 4. Create Inverse Propensity Weight

In propensity score matching, a large proportion of observations are not counted in the final frequency table because they are not matched. And this is due to a difference in the number of treatment groups and control groups. Using inverse propensity score weight, we can keep all this information by assigning different weight to different observations. Here we use to Average Treatment Effect (ATE) as our propensity weight, which is generally the quantity estimated when running a randomized study, and can be computed by
$$
w_{ATE}(x) = \frac{T}{p(x)} + \frac{1 - T}{1 - p(x)}
$$


## Software Tutorial {.tabset .tabset-pills .tabset-fade}
### Python 
```{r setup_py, include=FALSE}
knitr::opts_chunk$set(message = FALSE, echo = TRUE)
library(reticulate)
library(tidyverse)
use_python("/opt/anaconda3/bin/python")
```


In this `python` tutorial, we mainly use the following package. `numpy` and `pandas` are used to read and process the data, `sklearn.linear_model` is used to fit the logistic regression model, `statsmodels.stats.weightstats` is used to construct the t-test with sample weight. All the algorithms related to propensity score weighting in this tutorial are implemented in `python`, but the tables and figures are visualized by `R(tidyverse)` using the output extracted from `python`. All the `python` variables are stored in a `R` list called `py` automatically and can be extracted by `$`.


```{python load_package, engine.path="/opt/anaconda3/bin/python"}
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from statsmodels.stats.weightstats import ttest_ind
```


```{python read_data, engine.path="/opt/anaconda3/bin/python"}
nhanes = pd.read_csv('./data/nhanes.csv')
nhanes_X = nhanes.drop(columns=['id', 'heart_attack','diabete','weight'])
nhanes_diab = nhanes['diabete']
weight = nhanes['weight']
```


#### Estimate the Propensity Score by Fitting a Logistic Regression Model
```{python lg, engine.path="/opt/anaconda3/bin/python"}
lg = LogisticRegression(random_state=0, max_iter = 1000)
lg.fit(nhanes_X, nhanes_diab, sample_weight = weight)
prop_score = lg.predict_proba(nhanes_X)[:,1]
```

```{r py_psplot, fig.cap=cap,fig.height=4,fig.width=8,echo=FALSE}
cap = "**Figure 1:** Propensity score distribution by Treated/Control Groups"
ps = data.frame(
  p_score = py$prop_score,
  diabete = ifelse(py$nhanes_diab, "Diabetes", "No Diabetes")
)

ps %>%
  ggplot( aes(x = p_score) ) + 
  geom_histogram( aes(color = diabete, fill = diabete),
                      position = "identity", bins = 30, alpha = 0.3) +
  xlab("Propensity Score") + 
  ylab("Frequency") +
  theme_bw()
```

Through **Figure 1**, we can see that, compared with diabetes patient, the non-diabetes patients usually have lower propensity scores. If we compare the `heart attack` rate directly, it is very likely to lead to a misleading result. Hence, we need to implement the Propensity Score Weighting/Matching to reduce the impact of covariates.

#### Propensity Score Matching by Nearest Neighbor
```{python psmatch}
dia_idx = np.where(nhanes['diabete'].values==1)
non_dia_idx = np.where(nhanes['diabete'].values==0)
prop_score_logit = np.log(prop_score / (1 - prop_score))
std = np.std(prop_score_logit[dia_idx])
result = [0]*len(prop_score_logit[dia_idx])
for i in range(len(prop_score_logit[dia_idx])):
    dif = prop_score_logit[dia_idx][i] - prop_score_logit[non_dia_idx]
    dif[np.array(result)[np.array(result)!=0]] = 100
    min_val = min(abs(dif))
    if min_val > 0.2*std:
        result[i] = 0
    else:
        result[i] = np.where(abs(dif)==min_val)[0][0]
        
result = np.array(result)
dia_idx_matched = dia_idx[0][result!=0]
result = result[result!=0]
matched_idx = non_dia_idx[0][result]
heart_matched = nhanes['heart_attack'].values[matched_idx]
heart_non_dia = nhanes['heart_attack'].values[non_dia_idx]
heart_dia_matched = nhanes['heart_attack'].values[dia_idx_matched]
```


```{python ttestpy}
ttest_match = ttest_ind(heart_dia_matched, heart_matched, usevar='unequal', 
                        weights=(weight[dia_idx_matched], weight[matched_idx]))
```

#### Estimate the Propensity Weights
```{python psweight}
ps_weight = nhanes['diabete']/prop_score + (1 - nhanes['diabete'])/(1 - prop_score)
```

#### Balance Checking
```{python balcheck}
col = list(nhanes_X.columns)
result_mean_after = []
result_sd_after = []
for i in nhanes_X.columns:
    re_m = [np.average(nhanes_X[i][matched_idx],
                       weights=nhanes['weight'][matched_idx]), 
            np.average(nhanes_X[i][dia_idx_matched],
                       weights=nhanes['weight'][dia_idx_matched])]
    re_sd = [np.sqrt(np.average((nhanes_X[i][matched_idx]-re_m[0])**2, 
                                weights=nhanes['weight'][matched_idx])), 
             np.sqrt(np.average((nhanes_X[i][dia_idx_matched]-re_m[1])**2, 
                                weights=nhanes['weight'][dia_idx_matched]))]
    result_mean_after.append(re_m)
    result_sd_after.append(re_sd)

result_mean_before = []
result_sd_before = []
for i in nhanes_X.columns:
    re_m = [np.average(nhanes_X[i][non_dia_idx[0]],
                       weights=nhanes['weight'][non_dia_idx[0]]), 
            np.average(nhanes_X[i][dia_idx[0]],
                       weights=nhanes['weight'][dia_idx[0]])]
    re_sd = [np.sqrt(np.average((nhanes_X[i][non_dia_idx[0]]-re_m[0])**2, 
                                 weights=nhanes['weight'][non_dia_idx[0]])), 
             np.sqrt(np.average((nhanes_X[i][dia_idx[0]]-re_m[1])**2, 
                                 weights=nhanes['weight'][dia_idx[0]]))]
    result_mean_before.append(re_m)
    result_sd_before.append(re_sd)
```



#### {.tabset .tabset-pills .tabset-fade}
##### Table 1: Before Matching
```{r tab1, echo=FALSE}
cap1 = "**Table 1:** Proportion of Heat Attack with Original Control Group"
tab_not_match = py$nhanes %>%
  dplyr::select(heart_attack, diabete, weight) %>%
  group_by(diabete, heart_attack) %>%
  summarise(freq = sum(weight)) %>%
  mutate(
    prop = freq/sum(freq),
    freq_p = paste0(sprintf("%9.0f", freq),"(",
                    sprintf("%5.1f", prop*100),"%)")
  )%>%
  dplyr::select(-freq,-prop)

as_tibble_col(c("No","Yes"),column_name = "Heart Attack") %>%
  bind_cols(tab_not_match[1:2,3]) %>%
  bind_cols(tab_not_match[3:4,3]) %>%
  knitr::kable(format = "html", align = "lrr", caption = cap1,
               col.names = c("Heart Attack","Non-diabetes","Diabetes")) %>%
  kableExtra::kable_styling('striped', full_width = TRUE)
```

##### Table 2: After Matching
```{r tab2, echo=FALSE}
cap2 = "**Table 2:** Proportion of Heat Attack with Matched Control Group"
tab_match = py$nhanes[c(py$dia_idx_matched+1,py$matched_idx+1),] %>%
  dplyr::select(heart_attack, diabete, weight) %>%
  group_by(diabete, heart_attack) %>%
  summarise(freq = sum(weight)) %>%
  mutate(
    prop = freq/sum(freq),
    freq_p = paste0(sprintf("%9.0f", freq),"(",
                    sprintf("%5.1f", prop*100),"%)")
  )%>%
  dplyr::select(-freq,-prop)
as_tibble_col(c("No","Yes"),column_name = "Heart Attack") %>%
  bind_cols(tab_match[1:2,3]) %>%
  bind_cols(tab_match[3:4,3]) %>%
  knitr::kable(format = "html", align = "lrr", caption = cap2,
                col.names = c("Heart Attack","Non-diabetes","Diabetes")) %>%
  kableExtra::kable_styling('striped', full_width = TRUE)
```


##### Table 3: T-test
```{r tab3, echo=FALSE}
cap3 = "**Table 3:** Result of T-test"
as_tibble_row(c(tstat = py$ttest_match[[1]], 
                pvalue = py$ttest_match[[2]], 
                df = py$ttest_match[[3]] )) %>%
  knitr::kable(format = "html", align = "rr", caption = cap3,
               col.names = c("T Statistic", "p-value", "degree of freedom")) %>%
  kableExtra::kable_styling('striped', full_width = TRUE)
```

##### Table 4: Inverse Weighting
```{r tab4, echo=FALSE}
cap4 = paste0("**Table 4:** Proportion of Heat Attack with ", 
              "Inverse Propensity Score Weighting")
tab_weight = py$nhanes %>%
  dplyr::select(heart_attack, diabete, weight) %>%
  bind_cols(ps_weight = py$ps_weight) %>%
  group_by(diabete, heart_attack) %>%
  summarise(freq = sum(weight*ps_weight)) %>%
  mutate(
    prop = freq/sum(freq),
    freq_p = paste0(sprintf("%9.0f", freq),"(",
                    sprintf("%5.1f", prop*100),"%)")
  )%>%
  dplyr::select(-freq,-prop)
as_tibble_col(c("No","Yes"),column_name = "Heart Attack") %>%
  bind_cols(tab_weight[1:2,3]) %>%
  bind_cols(tab_weight[3:4,3]) %>%
  knitr::kable(format = "html", align = "lrr", caption = cap4,
                col.names = c("Heart Attack","Non-diabetes","Diabetes")) %>%
  kableExtra::kable_styling('striped', full_width = TRUE)
```
##### Table 5: Balance Checking

```{r py_balchech,echo=FALSE}
cap5 = "**Table 5:** Balance Checking Table before and after matching"
result_mean_after = do.call("rbind",py$result_mean_after)
result_sd_after = do.call("rbind",py$result_sd_after)
result_mean_before = do.call("rbind",py$result_mean_before)
result_sd_before = do.call("rbind",py$result_sd_before)
py$col %>%
  bind_cols(paste0(sprintf("%5.3f", result_mean_before[,1]),"(",
                       sprintf("%5.3f", result_sd_before[,1]),")")) %>%
  bind_cols(paste0(sprintf("%5.3f", result_mean_before[,2]),"(",
                       sprintf("%5.3f", result_sd_before[,2]),")")) %>%
  bind_cols(paste0(sprintf("%5.3f", result_mean_after[,1]),"(",
                       sprintf("%5.3f", result_sd_after[,1]),")")) %>%
  bind_cols(paste0(sprintf("%5.3f", result_mean_after[,2]),"(",
                       sprintf("%5.3f", result_sd_after[,2]),")")) %>%
  knitr::kable(format = "html", align = "lrrrr", caption = cap5,
               col.names = c("Covariate","Non-diabetes","Diabetes",
                             "Non-diabetes","Diabetes")) %>%
  kableExtra::kable_styling('striped', full_width = TRUE) %>%
  kableExtra::add_header_above(c(" " = 1, "Before Matching" = 2, 
                                 "After Matching" = 2))
```


#### Result Interpretation
Through **Table 1**, **Table 2** and **Table 4**, we can see that before matching/weighting, the rate of `heart attack` in diabetes patients is around 7 times larger than the non-diabetes patients. After matching/weighting, this rate decreases to only 2-3 times larger, which indicates that our matching/weighting significantly reduce the effect of the covariates. **Table 5** also shows similar result. Before matching, the `heart_attack` rate in `relative_heart_attack`, `age`, `bmi`, `blood_press`, `blood_press2`, `hyper_med`, `hbq_med`, `year_smoke` and `year_hyper` are significantly different between diabetes patients and non-diabetes patients. However, after matching, the rates in all corresponding covariates look similar, which is another evidence of the effect of propensity score matching. **Table 3** shows the t test result, which indicates that after matching, the `heart attack` rate in diabetes patients is still higher than the non-diabetes patients.

### R
#### Libraries:    
```{r libraries, message = FALSE}
# libraries: ------------------------------------------------------------------
library(MatchIt)
library(survey)
library(tidyverse)
library(ggplot2)
library(tableone)
```
  * `MatchIt`: The package has `matchit` function, which is used to perform propensity score matching.  
  * `survey`: `svydesign` and `svyglm` functions in this package are used to perform logistic regression with sample weights.  
  * `tidyverse`: The package used for data I/O and preparation.  
  * `ggplot2`: The package used for data visualization.  
  * `tableone`: The package used for balance generating balance checking tables.
       
#### Step 1 - Pre-evaluating before matching   
```{r data, message = FALSE}
# data: -----------------------------------------------------------------------
nhanes = read_delim("./data/nhanes.csv", delim = ",")
nhanes = nhanes %>%
  mutate(
    diabete = as.factor(diabete),
    heart_attack = as.factor(heart_attack),
    gender = ifelse(gender == 2, 1, 0),
  )
```
  
```{r check balance 1}
var = c("relative_heart_attack", "gender", "age", "race", "edu", "annual_income",
        "bmi", "smoke_life", "phy_vigorous", "phy_moderate", "blood_press",
        "blood_press2", "hyper_med", "high_chol", "meadial_access", "cover_hc",
        "health_diet", "year_smoke", "year_hyper")
match_tab1 = CreateTableOne(vars=var, strata="diabete", data=nhanes, test=FALSE)
print(match_tab1, smd = TRUE)  
```
  * We use the pre-matched data to do balance check between treatment and control groups. We computed the average standardized differences (SMD) for each covariates. From the table, we can find that, for most of the covariates, there are pretty large differences between treatment and control groups.   
     
#### Step 2 - Propensity score estimation     
```{r p_score, warning = FALSE, message = FALSE}
## Logistic regression for treatment ~ pretreatment:
design_ps = svydesign( ids = ~1, weights = ~weight, data = nhanes )
ps_mod = svyglm(diabete ~ relative_heart_attack + gender + age + race + edu 
                + annual_income + bmi + smoke_life + phy_vigorous + phy_moderate
                + blood_press + blood_press2 + hyper_med + hbq_med + high_chol 
                + meadial_access + cover_hc + health_diet + year_smoke + year_hyper,
                family = binomial(),
                design = design_ps)
## Get the propensity score:
p_score = predict(ps_mod, type = "response")
```
  * We estimate the propensity score by running a logistic model, where the outcome variable `diabete` is a binary variable indicating treatment status and all the other covariates are used as predictors. In order to include sample weights in the model, we also used `svydesign` and `svyglm` functions in the `survey` package.   
  * With the logistic model, we can calculate the propensity score, which is simply the predicted probability of being treated.   
  * The distribution of the generated propensity scores in treatment/control groups are shown below. From figure 1, we can find that there are some overlaps between the two groups, which guarantees the propensity score matching sample.  
    
<details>
<summary> Click to view `code for figure 1`. </summary>
```{r propensity score distribution}
cap1 = "**figure 1.** *Propensity score distribution by Treated/Control Groups*"
ps = data.frame(
  p_score = ps_mod$fitted.values,
  Diabete = ifelse(ps_mod$model$diabete == 1, "Diabetes", "No Diabetes")
)

fig1 = ps %>%
  ggplot( aes(x = p_score) ) + 
  geom_histogram( aes(color = Diabete, fill = Diabete),
                      position = "identity", bins = 30, alpha = 0.3) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800")) +
  xlab("Propensity Score") + 
  ylab("Frequency") +
  theme_bw()
```
</details>

```{r fig1, fig.cap=cap1}
cap1 = "**figure 1.** *Propensity score distribution by Treated/Control Groups*"
print(fig1)
```

#### Step 3 - Propensity score match   
```{r p_score matching}
nhanes_ps = nhanes %>% mutate( p_score = p_score)
match_mod = matchit(ps_mod$formula,
                    distance = 'logit',
                    method = "nearest", 
                    caliper = .2,
                    ratio = 1,
                    data = nhanes_ps,
                    replace = FALSE)
ps_match = match.data(match_mod)
```
  * We can use propensity score matching to generate a sub-sample, which minimizes the covariates' difference between treatment group and control group. The `matchit` function in `MatchIt` package can estimate the propensity score internally and match observations based on different methods. The method we chose in this tutorial example is nearest neighborhood.  
    
#### Step 4 - Balance Checking after matching  
```{r check balance 2}
var = c("relative_heart_attack", "gender", "age", "race", "edu", "annual_income",
        "bmi", "smoke_life", "phy_vigorous", "phy_moderate", "blood_press",
        "blood_press2", "hyper_med", "high_chol", "meadial_access", "cover_hc",
        "health_diet", "year_smoke", "year_hyper")
match_tab = CreateTableOne(vars=var, strata="diabete", data=ps_match, test=FALSE)
print(match_tab, smd = TRUE)  
```
  * By using the same method of the pre-evaluation mentioned in Step 1, we can do the balance checking again using the matched sample. From the table, it's obvious to observe significant decreases in SMD of all covariates. The difference between treatment group and control group became insignificant with the matched sample.  
    
#### Step 5 - Comparison between pre_match data and matched data   

#### Result tables {.tabset}  
##### Proportion of Heat Attack with Pre-matched Group  
<details>
<summary> Click to view `code for Table 1`. </summary>
```{r tab1r}
cap2 = "**Table 1.** *Proportion of Heat Attack with Pre-matched Group*"
tab_pre_mt = nhanes %>%
  group_by(diabete, heart_attack) %>%
  summarize(n = sum(weight), .groups = "drop_last") %>%
  mutate(
    prop = 100*(n / sum(n))
  ) %>%
  transmute(
    `Heart Attack` = ifelse(heart_attack == 1, "YES", "NO"),
    Diabetes = ifelse(diabete == 1, "Diabetes", "NoDiabetes"),
    prop = sprintf('%10.0f (%4.2f%%)', n, prop)
  ) %>%
  pivot_wider(
    id_cols = `Heart Attack`,
    names_from = Diabetes,
    values_from = prop
  ) %>%
  knitr::kable(format = 'html', caption = cap2) %>%
  kableExtra::kable_styling("striped", full_width = TRUE) %>%
  kableExtra::add_header_above(
    header = c("Proportion of Heat Attack with Pre-matched Group" = 3)
  )
```
</details>

```{r table1, echo = FALSE}
tab_pre_mt
```

##### Proportion of Heat Attack with Matched Group  
<details>
<summary> Click to view `code for Table2`. </summary>
```{r tab2r}
cap3 = "**Table 2.** *Proportion of Heat Attack with Matched Group*"
tab_mt = ps_match %>%
  group_by(diabete, heart_attack) %>%
  summarize(n = sum(weight), .groups = "drop_last") %>%
  mutate(
    prop = 100*(n / sum(n))
  ) %>%
  transmute(
    `Heart Attack` = ifelse(heart_attack == 1, "YES", "NO"),
    Diabetes = ifelse(diabete == 1, "Diabetes", "NoDiabetes"),
    prop = sprintf('%10.0f (%4.2f%%)', n, prop)
  ) %>%
  pivot_wider(
    id_cols = `Heart Attack`,
    names_from = Diabetes,
    values_from = prop
  ) %>%
  knitr::kable(format = 'html', caption = cap3) %>%
  kableExtra::kable_styling("striped", full_width = TRUE) %>%
  kableExtra::add_header_above(
    header = c("Proportion of Heat Attack with Matched Group" = 3)
  )
```
</details>

```{r table2, echo = FALSE}
tab_mt
```

##### t-test
```{r ttest}
heart_attack_d = ps_match %>%
  filter(diabete == 1)

heart_attack_nd = ps_match %>%
  filter(diabete == 0) 

print(t.test(as.numeric(heart_attack_d$heart_attack), as.numeric(heart_attack_nd$heart_attack)))
```
  * With the t-test result, we reject the hypothesis that the mean value of heart attack in two groups are equal. So with the matched data, the heart attack rate in diabete group is still higher than the non-diabete group.  
  
#### Step 6 - Inverse propensity score weighting    
  * We also can generate the inverse propensity score weight to reduce the bias between treatment and control groups.  
  
<details>
<summary> Click to view `code for Table3`. </summary>
```{r ipw}
cap4 = "**Table 3.** *Proportion of Heat Attack with Inverse Propensity Weight*"
invert = nhanes_ps %>%
  select(diabete, heart_attack, weight, p_score) %>%
  mutate(
    inverse_wt = ifelse(diabete == 1, 1/p_score, 1/(1-p_score)),
    new_wt = weight * inverse_wt
  ) %>% 
  group_by(diabete, heart_attack) %>%
  summarize(n = sum(new_wt), .groups = "drop_last") %>%
  mutate(
    prop = 100*(n / sum(n))
  ) %>%
  transmute(
    `Heart Attack` = ifelse(heart_attack == 1, "YES", "NO"),
    Diabetes = ifelse(diabete == 1, "Diabetes", "NoDiabetes"),
    prop = sprintf('%10.0f (%4.2f%%)', n, prop)
  ) %>%
  pivot_wider(
    id_cols = `Heart Attack`,
    names_from = Diabetes,
    values_from = prop
  ) %>%
  knitr::kable(format = 'html', caption = cap4) %>%
  kableExtra::kable_styling("striped", full_width = TRUE) %>%
  kableExtra::add_header_above(
    header = c("Proportion of Heat Attack with Inverse Propensity Weight" = 3)
  )
```
</details> 

```{r table3, echo = FALSE}
invert
```


### SAS

#### README

In this `SAS` tutorial, we mainly use the following procedure. `proc import` and `macros` `csvexport`(Contributed by Dr.Henderson) are used to read and export the data. `proc logistic` is used to fit the logistic regression model and predicts propensity score, and `gmatch`(Contributed by The Division of Biostatistics at the Mayo Clinic) perfroms the greedy matching.   
     
Then we use `proc gchart` to reveal the structure of the data, thereafter using `proc means` along with `proc ttest` to compute means and construct the t-test with sample weight.     
        
This work is done primarily in `SAS`, with the exception that the write up and figures or tables  for visualization are produced in R.

#### SAS Script

<details>
 <summary> `GroupProject_SAS_Hongfan.sas` </summary>
```{r GroupProject_SAS_Hongfan.sas, comment=""}
readLines("./SAS/GroupProject_SAS_Hongfan.sas")
```
</details>

#### Load Files

```{r load_sas, message=FALSE}
path = './SAS/'
prematch_path = sprintf('%s/output/freq_table.csv', path)
matched_path = sprintf('%s/output/freq_table_merge.csv', path)
inverseweight_path = sprintf('%s/output/ps_match_inverse_table.csv', path)
matched_sum_path = sprintf('%s/output/matched_summary.csv', path)
pre_sum_path = sprintf('%s/output/pre_summary.csv', path)
conflimits_path = sprintf('%s/output/conflimits.csv', path)
ttest_path = sprintf('%s/output/ttest.csv', path)

age_pre = sprintf('%s/graph/age_before.png', path)
age_after = sprintf('%s/graph/age_after.png', path)

hyper_pre = sprintf('%s/graph/hyper_before.png', path)
hyper_after = sprintf('%s/graph/hyper_after.png', path)

smoke_pre = sprintf('%s/graph/smoke_before.png', path)
smoke_after = sprintf('%s/graph/smoke_after.png', path)

press1_pre = sprintf('%s/graph/press_before.png', path)
press1_after = sprintf('%s/graph/press_after.png', path)

press2_pre = sprintf('%s/graph/press2_before.png', path)
press2_after = sprintf('%s/graph/press2_after.png', path)

ps_distribution = sprintf('%s/graph/ps_combined.png', path)

prematch = read_delim(prematch_path, delim = ',')
matched = read_delim(matched_path, delim = ',')
inverseweight = read_delim(inverseweight_path, delim = ',')
matched_sum = read_delim(matched_sum_path, delim = ',')
pre_sum = read_delim(pre_sum_path, delim = ',')
conflimits = read_delim(conflimits_path, delim = ',')
ttest = read_delim(ttest_path, delim = ',')
```

#### 1. Distribution of Propensity Score

```{r ps_sas}
knitr::include_graphics(ps_distribution)
```

#### Explanation

From the figure above, we see that there is a huge difference in the distribution of propensity score of two groups. If we compare the heart attack rate directly, a misleading result may occur. Therefore, we need to implement the Propensity Score Matching/Weighting to achieve balance or comparability of treatment groups in terms of their measured pretreatment covariates, and thereby controls for confounding bias in estimating treatment effects.

#### 2. Comparison Table Between Prematch Data And Macthed Data {.tabset .tabset-fade .tabset-pills}

```{r tables_sas, message=FALSE}
tab = function(df, cap = "hello"){
  df %>%
  mutate(
    `Heart Attack` = ifelse(heart_attack == 1, "YES", "NO"),
    diabetes = ifelse(diabetes == 1, "Diabetes", "Non-Diabetes")
    ) %>%
  group_by(diabetes) %>%
  mutate(pct = COUNT / sum(COUNT)) %>%
  mutate(COUNT_PCT = sprintf('%.0f (%.2f%s)', COUNT, pct * 100, "%")) %>%
  select(`Heart Attack`, diabetes, COUNT_PCT) %>%
  pivot_wider(id_cols = `Heart Attack`,
               names_from = 'diabetes', 
               values_from = 'COUNT_PCT') %>%
  knitr::kable(format = 'html', caption = cap) %>%
  kableExtra::kable_styling("striped", full_width = TRUE)
}
```

##### Before Match

```{r table_1_sas}
cap = paste0(
"**Table 1.** Proportion of Heat Attack with Pre-matched Group"
)
tab(prematch,
    cap = cap
    )
```

##### After Match

```{r table_2_sas}
cap = paste0(
"**Table 2.** Proportion of Heat Attack with Matched Group"
)
tab(matched,
    cap = cap
    )
```

##### Using Iverse Propensity Weight

```{r table_3_sas}
cap = paste0(
"**Table 3.** Proportion of Heat Attack with Inverse Propensity Weight"
)
tab(inverseweight,
    cap = cap
    )
```


#### Explanation

These tables show how `Propensity Score Matching/Weighting` eliminate or reduce the effect of pre-treatment covariates on estimating treatment effect.     
We can see that before matching/weighting, the rate of heart attack in diabetes patients is around 7 times larger than the non-diabetes patients. After matching/weighting, this rate decreases to only 2-3 times larger. This tells us the diabetes does have an effect on heart attack, but not that much.

#### 3. Comparison Graph Between Prematch Data And Macthed Data {.tabset .tabset-fade .tabset-pills}

##### Age

```{r age_sas}
knitr::include_graphics(age_pre)
knitr::include_graphics(age_after)
```

##### Year of Hyper

```{r hyper_sas}
knitr::include_graphics(hyper_pre)
knitr::include_graphics(hyper_after)
```

##### Year of Smoke

```{r smoke_sas}
knitr::include_graphics(smoke_pre)
knitr::include_graphics(smoke_after)
```

##### Blood Press

```{r bloodpress_sas}
knitr::include_graphics(press1_pre)
knitr::include_graphics(press1_after)
```

##### Blood Press 2

```{r bloodpress2_sas}
knitr::include_graphics(press2_pre)
knitr::include_graphics(press2_after)
```

#### Explanation

These graphs give us a direct and clear sense of how `Propensity Score Matching/Weighting` balance the pre-treatment covariates. Here I select `age`, `year of smoke`, `year of hyper`,
`blood pressure` to illustrate this fact. Before matching, the distribution of these variables differs heavily on two groups. After matching, these pre-treatment covariates seems to be unified, which helps us to mimic the situations of Randomized clinical trials(RCT).

#### 4. Balance Checking For All Covariates And T Test {.tabset .tabset-fade .tabset-pills}

##### MEAN/STD

```{r Balance_sas}
n = (length(names(matched_sum)) - 1) / 3
pre_data = NULL
matched_data = NULL

for(i in 1:n){
  data0 = pre_sum %>%
    select(1, 2+3*(i-1), 3+3*(i-1), 4+3*(i-1))
  names(data0) = c("diabetes", "variable", "mean", "std")
  data_wider = data0 %>% 
    mutate(mean_std = sprintf("%.3f(%.3f)", mean, std),
           diabetes = ifelse(diabetes == "Yes",
                             "Diabetes",
                             "Non-diabetes")
    ) %>%
    select(diabetes, variable, mean_std) %>%
    pivot_wider(names_from = diabetes,
                values_from = mean_std)
  pre_data = bind_rows(pre_data, data_wider)
}

for(i in 1:n){
  data0 = matched_sum %>%
    select(1, 2+3*(i-1), 3+3*(i-1), 4+3*(i-1))
  names(data0) = c("diabetes", "variable", "mean", "std")
  data_wider = data0 %>% 
    mutate(mean_std = sprintf("%.3f(%.3f)", mean, std),
           diabetes = ifelse(diabetes == "Yes",
                             "Diabetes",
                             "Non-diabetes")
           ) %>%
    select(diabetes, variable, mean_std) %>%
    pivot_wider(names_from = diabetes,
                values_from = mean_std)
  matched_data = bind_rows(matched_data, data_wider)
}

tab = left_join(pre_data, matched_data, by = "variable")
cap_tab = paste(
  "**Table 4.** *The mean of all variables before and after matching.*",
  "Numbers in parantheses are standard deviation."
)
cn = c('Covariate',
       'Non-diabetes', 'diabetes',
       'Non-diabetes', 'Non-diabetes'
       )
tab %>%
  knitr::kable(
    format = 'html', 
    escape = FALSE, 
    align = 'lcccc',
    col.names = cn,
    cap = cap_tab
  ) %>%
  kableExtra::kable_styling("striped", full_width = TRUE) %>%
  kableExtra::add_header_above(header = c(' ' = 1,
                                          'Before Matching' = 2,
                                          'After Matching' = 2)
                               )
```

##### T-TEST

```{r ttest_sas}
tab1 = conflimits %>%
  select(Variable, Class, Method, Variances, Mean) %>%
  left_join(ttest %>% 
              select(-Variable),
            by = c("Method", "Variances")
            ) %>%
  replace_na(list(Method = "-",
                  Variances = "-",
                  tValue = "-",
                  DF = "-",
                  Probt = "-")
             )
cap_tab1 = paste(
  "**Table 5.** *Perform t test to show significance using two method.*",
  "Diabetes indeed has an effect on heart attack."
)
tab1 %>%
  knitr::kable(format = 'html', caption = cap_tab1) %>%
  kableExtra::kable_styling("striped", full_width = TRUE)
```

#### Explanation

Finally, I provides two tables here. The first one is the mean-std pairs of all covariates which shows the difference of two groups. The second one shows the t test result, which indicates that after matching, the heart attack rate in diabetes patients is still higher than the non-diabetes patients.     
So now we can answer the question at the beginning: Adult patients with diabetes do have higher risk for heart attack (myocardial infarction) in the United States.


### STATA
```{stata s1, collectcode=TRUE}
import delimited "./data/nhanes.csv", encoding(ISO-8859-1)
```
#### Initial Data Balance:
This will allow us to determine, which covariates will be useful when calculating the propensity score. 
* To-Do 
  + Create Confidence Intervals for all of the variables in order to know which to choose in our final model
  + create a standardized balance table and compare the means 
```{stata s2, collectcode=TRUE}
logit heart_attack relative_heart_attack gender age race edu annual_income weight bmi diabete smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper
 
ttest diabete, by(heart_attack)
```

#### I. Propensity score estimation:

```{stata s3, collectcode=TRUE, results="hide"}
pscore diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper, pscore(pc_pscore) blockid(pc_block) detail
psgraph, treated(diabete)pscore(pc_pscore)
```

#### II. Propensity score matching/weighting:
* To-Do
  + create graphics 
  + for matching, I will create a line graph and juxtapose the untreated vs. treated 
  + for weighting, I will create two density graphs to compare 

##### Matching 

```{stata s4, collectcode=TRUE}
qui psmatch2 diabete, kernel outcome(heart_attack) pscore(pc_pscore)
```

##### Inverse Propensity Score Weighting 
```{stata s5, collectcode=TRUE}
qui dr heart_attack diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper, genvars
egen sumofweights = total(iptwt)
gen norm_weights = iptwt/sumofweights
```

#### III. Balance Checking:
* To-Do 
  + I will also a linear regression estimation using the teffects ra function 
  
#### Matched Data Balance 
```{stata s6, collectcode=TRUE}
psmatch2 diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper, out(heart_attack)
 
reg heart_attack relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper diabete [fweight = _weight]
 
teffects ipw (heart_attack) (diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper)
```

#### Inverse Weighting Balance

```{stata s7, collectcode=TRUE}
pbalchk diabete heart_attack diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper, wt(norm_weights)
 
teffects ipwra (heart_attack relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper) (diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper)
```

#### IV. Comparison between pre_match data and matched data.
* To-Do  
  + Create Graphs comparing pre-match data and match data 
  + Create graphs comparing pre-weighted data to weighted data 
  + standardized tables for both matched and weighted data to compare to initial data set


