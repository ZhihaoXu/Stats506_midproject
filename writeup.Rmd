---
title: "Stats 506, F20, Midterm Project Group 1"
author:
  - Hongfan Chen, chenhf@umich.edu
  - Rithu Uppalapati, rurithu@umich.edu
  - Zhihao Xu, xuzhihao@umich.edu
  - Yawen Hu, yawenhu@umich.edu
date: "`r format.Date(Sys.Date(), '%B %d, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, echo = TRUE)
library(reticulate)
library(tidyverse)
library(Statamarkdown)
use_python("/opt/anaconda3/bin/python")
```

## About

### Research Question
A propensity score is the **conditional probability** that a subject receives "treatment" given the subject’s observed covariates. When estimating treatment effects on a binary outcome, it may happen that the treatments are not randomly assigned to subjects, which is somewhat often the case in observational studies. Propensity scoring aims to mimic what happens in randomized controlled trials by balancing observed covariates between subjects in control and treatment groups.

The purpose of this tutorial is to introduce how to perform propensity score analyses. In the following sections we will use the data from the National Health and Nutrition Examination Survey ([NHANES](https://www.cdc.gov/nchs/nhanes/index.htm)). We will use the propensity score as a tool to figure out the following question:

> Whether or not adult patients with diabetes have higher risk for heart attack (myocardial infarction) in the United States?

Here’s are the main reasons why we choose this method: 

- This dataset is based on observational data but not experimental and thus has selection bias.
- There are many confounding variables, such as age, body mass index (BMI), year of smoking etc. Also, among other variables, like race or income that seem to be irrelevant with this question may also have the potential to impact our outcome and be confounding variables.


### Data Description

From the [NHANES](https://www.cdc.gov/nchs/nhanes/index.htm) dataset, we choose the following variable as the predictors, outcome and treatment.

Outcome: `heart_attack`  
Treatment: `diabetes`  

Predictors:   

|  Variable               | Description                                         |
| ----------------------- | ----------------------------------------------------|
| `relative_heart_attack` | Relatives have heart attack or not                  |
| `gender`                | Gender of the participant                           |
| `age`                   | Age of the participant                              |
| `race`                  | Race of the participant                             |
| `edu`                   | Education Level                                     | 
| `annual_income`         | Annual Income                                       | 
| `bmi`                   | Body Mass Index                                     |
| `smoke_life`            | Smoked at least 100 cigarettes in life or not       |
| `year_smoke`            | Year of smoke                                       |
| `phy_vigorous`          | Doing vigorous work activity or not                 | 
| `phy_moderate`          | Doing moderate work activity or not                 |
| `blood_press`           | Being told high blood pressure                      | 
| `blood_press2`          | Being told high blood pressure 2+ more times or not |
| `year_hyper`            | Year of hypertension                                | 
| `hyper_med`             | Taking hypertension medicine or not                 |
| `hbp_med`               | Taking HBP medicine or not                          | 
| `high_chol`             | Being told high cholesterol level or not            |
| `meadial_access`        | Being able to have medical access or nor            |
| `cover_hc`              | Covered by health care or not                       |
| `health_diet`           | Having a health diet or not                         |

**Note:** For all the binary variable here with value 1 and 0, 1 = Yes and 0 = No


## Tutorial Procedure
#### 1. Create Propensity Score
Just the same as doing a randomized controlled trial, we would want our treatment and control groups to have variables which have similar point estimates, such as roughly same mean age or mean BMI. Then Logistic Regression can be introduced to develop propensity scores, since it can represent the conditional probability that a patient receives the treatment given the observed covariates.

$$
p(x) = P(T=1|X_1, X_2, \ldots, X_n)
$$
Therefore, we create a logistic model in which we take treatment, namely diabetes, as our response, and the other variables (except heart_attack and weights) as our predictors. Then each observation is assigned with a probability on which we can perform our matching.  

Note that we are not overly focusing on how well our model predicts whether a patient receives treatment or not. Here, what is more important is that we include all predictor variables in the model that are correlated or may be correlated with our outcome. So based on this we can do our best to eliminate the bias caused by the pre-treatment characteristics of the dataset.

#### 2. Propensity Score Matching

Here we use the propensity score to create 1-1 mapping between treatment and control groups. We also identify a caliper, which is a defined width based on a proportion of the standard deviation of the logit of the propensity score. Each observation from the treatment group is matched to the nearest observation in the control group that has not yet been matched by propensity score. The observations must have propensity scores that are within the caliper distance of each other. Here we choose 0.2*standard deviation as caliper distance.

#### 3. Compare the Matched Control Group with the Original Control Group

Here we first compute the frequency table and the proportion of having heart attack for both the matched control group and the original control group. We can further use T-test to figure out whether the difference between the control group and the treatment group is statistically significant or not.

#### 4. Create Inverse Propensity Weight

In propensity score matching, a large proportion of observations are not counted in the final frequency table because they are not matched. And this is due to a difference in the number of treatment groups and control groups. Using inverse propensity score weight, we can keep all this information by assigning different weight to different observations. Here we use to Average Treatment Effect (ATE) as our propensity weight, which is generally the quantity estimated when running a randomized study, and can be computed by
$$
w_{ATE}(x) = \frac{T}{p(x)} + \frac{1 - T}{1 - p(x)}
$$


## Software Tutorial
## {.tabset .tabset-pills .tabset-fade}
### Python 
```{r setup_py, include=FALSE}
knitr::opts_chunk$set(message = FALSE, echo = TRUE)
library(reticulate)
library(tidyverse)
use_python("/opt/anaconda3/bin/python")
```


In this `python` tutorial, we mainly use the following package. `numpy` and `pandas` are used to read and process the data, `sklearn.linear_model` is used to fit the logistic regression model, `statsmodels.stats.weightstats` is used to construct the t-test with sample weight. All the algorithms related to propensity score weighting in this tutorial are implemented in `python`, but the tables and figures are visualized by `R(tidyverse)` using the output extracted from `python`. All the `python` variables are stored in a `R` list called `py` automatically and can be extracted by `$`.


```{python load_package, engine.path="/opt/anaconda3/bin/python"}
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from statsmodels.stats.weightstats import ttest_ind
```


```{python read_data, engine.path="/opt/anaconda3/bin/python"}
nhanes = pd.read_csv('./data/nhanes.csv')
nhanes_X = nhanes.drop(columns=['id', 'heart_attack','diabete','weight'])
nhanes_diab = nhanes['diabete']
weight = nhanes['weight']
```


#### Estimate the Propensity Score by Fitting a Logistic Regression Model
```{python lg, engine.path="/opt/anaconda3/bin/python"}
lg = LogisticRegression(random_state=0, max_iter = 1000)
lg.fit(nhanes_X, nhanes_diab, sample_weight = weight)
prop_score = lg.predict_proba(nhanes_X)[:,1]
```

```{r py_psplot, fig.cap=cap,fig.height=4,fig.width=8,echo=FALSE}
cap = "**Figure 1:** Propensity score distribution by Treated/Control Groups"
ps = data.frame(
  p_score = py$prop_score,
  diabete = ifelse(py$nhanes_diab, "Diabetes", "No Diabetes")
)

ps %>%
  ggplot( aes(x = p_score) ) + 
  geom_histogram( aes(color = diabete, fill = diabete),
                      position = "identity", bins = 30, alpha = 0.3) +
  xlab("Propensity Score") + 
  ylab("Frequency") +
  theme_bw()
```

Through **Figure 1**, we can see that, compared with diabetes patient, the non-diabetes patients usually have lower propensity scores. If we compare the `heart attack` rate directly, it is very likely to lead to a misleading result. Hence, we need to implement the Propensity Score Weighting/Matching to reduce the impact of covariates.

#### Propensity Score Matching by Nearest Neighbor
```{python psmatch}
dia_idx = np.where(nhanes['diabete'].values==1)
non_dia_idx = np.where(nhanes['diabete'].values==0)
prop_score_logit = np.log(prop_score / (1 - prop_score))
std = np.std(prop_score_logit[dia_idx])
result = [0]*len(prop_score_logit[dia_idx])
for i in range(len(prop_score_logit[dia_idx])):
    dif = prop_score_logit[dia_idx][i] - prop_score_logit[non_dia_idx]
    dif[np.array(result)[np.array(result)!=0]] = 100
    min_val = min(abs(dif))
    if min_val > 0.2*std:
        result[i] = 0
    else:
        result[i] = np.where(abs(dif)==min_val)[0][0]
        
result = np.array(result)
dia_idx_matched = dia_idx[0][result!=0]
result = result[result!=0]
matched_idx = non_dia_idx[0][result]
heart_matched = nhanes['heart_attack'].values[matched_idx]
heart_non_dia = nhanes['heart_attack'].values[non_dia_idx]
heart_dia_matched = nhanes['heart_attack'].values[dia_idx_matched]
```


```{python ttest}
ttest_match = ttest_ind(heart_dia_matched, heart_matched, usevar='unequal', 
                        weights=(weight[dia_idx_matched], weight[matched_idx]))
```

#### Estimate the Propensity Weights
```{python psweight}
ps_weight = nhanes['diabete']/prop_score + (1 - nhanes['diabete'])/(1 - prop_score)
```

#### Balance Checking
```{python balcheck}
col = list(nhanes_X.columns)
result_mean_after = []
result_sd_after = []
for i in nhanes_X.columns:
    re_m = [np.average(nhanes_X[i][matched_idx],
                       weights=nhanes['weight'][matched_idx]), 
            np.average(nhanes_X[i][dia_idx_matched],
                       weights=nhanes['weight'][dia_idx_matched])]
    re_sd = [np.sqrt(np.average((nhanes_X[i][matched_idx]-re_m[0])**2, 
                                weights=nhanes['weight'][matched_idx])), 
             np.sqrt(np.average((nhanes_X[i][dia_idx_matched]-re_m[1])**2, 
                                weights=nhanes['weight'][dia_idx_matched]))]
    result_mean_after.append(re_m)
    result_sd_after.append(re_sd)

result_mean_before = []
result_sd_before = []
for i in nhanes_X.columns:
    re_m = [np.average(nhanes_X[i][non_dia_idx[0]],
                       weights=nhanes['weight'][non_dia_idx[0]]), 
            np.average(nhanes_X[i][dia_idx[0]],
                       weights=nhanes['weight'][dia_idx[0]])]
    re_sd = [np.sqrt(np.average((nhanes_X[i][non_dia_idx[0]]-re_m[0])**2, 
                                 weights=nhanes['weight'][non_dia_idx[0]])), 
             np.sqrt(np.average((nhanes_X[i][dia_idx[0]]-re_m[1])**2, 
                                 weights=nhanes['weight'][dia_idx[0]]))]
    result_mean_before.append(re_m)
    result_sd_before.append(re_sd)
```



#### {.tabset .tabset-pills .tabset-fade}
##### Table 1: Before Matching
```{r tab1, echo=FALSE}
cap1 = "**Table 1:** Proportion of Heat Attack with Original Control Group"
tab_not_match = py$nhanes %>%
  dplyr::select(heart_attack, diabete, weight) %>%
  group_by(diabete, heart_attack) %>%
  summarise(freq = sum(weight)) %>%
  mutate(
    prop = freq/sum(freq),
    freq_p = paste0(sprintf("%9.0f", freq),"(",
                    sprintf("%5.1f", prop*100),"%)")
  )%>%
  dplyr::select(-freq,-prop)

as_tibble_col(c("No","Yes"),column_name = "Heart Attack") %>%
  bind_cols(tab_not_match[1:2,3]) %>%
  bind_cols(tab_not_match[3:4,3]) %>%
  knitr::kable(format = "html", align = "lrr", caption = cap1,
               col.names = c("Heart Attack","Non-diabetes","Diabetes")) %>%
  kableExtra::kable_styling('striped', full_width = TRUE)
```

##### Table 2: After Matching
```{r tab2, echo=FALSE}
cap2 = "**Table 2:** Proportion of Heat Attack with Matched Control Group"
tab_match = py$nhanes[c(py$dia_idx_matched+1,py$matched_idx+1),] %>%
  dplyr::select(heart_attack, diabete, weight) %>%
  group_by(diabete, heart_attack) %>%
  summarise(freq = sum(weight)) %>%
  mutate(
    prop = freq/sum(freq),
    freq_p = paste0(sprintf("%9.0f", freq),"(",
                    sprintf("%5.1f", prop*100),"%)")
  )%>%
  dplyr::select(-freq,-prop)
as_tibble_col(c("No","Yes"),column_name = "Heart Attack") %>%
  bind_cols(tab_match[1:2,3]) %>%
  bind_cols(tab_match[3:4,3]) %>%
  knitr::kable(format = "html", align = "lrr", caption = cap2,
                col.names = c("Heart Attack","Non-diabetes","Diabetes")) %>%
  kableExtra::kable_styling('striped', full_width = TRUE)
```


##### Table 3: T-test
```{r tab3, echo=FALSE}
cap3 = "**Table 3:** Result of T-test"
as_tibble_row(c(tstat = py$ttest_match[[1]], 
                pvalue = py$ttest_match[[2]], 
                df = py$ttest_match[[3]] )) %>%
  knitr::kable(format = "html", align = "rr", caption = cap3,
               col.names = c("T Statistic", "p-value", "degree of freedom")) %>%
  kableExtra::kable_styling('striped', full_width = TRUE)
```

##### Table 4: Inverse Weighting
```{r tab4, echo=FALSE}
cap4 = paste0("**Table 4:** Proportion of Heat Attack with ", 
              "Inverse Propensity Score Weighting")
tab_weight = py$nhanes %>%
  dplyr::select(heart_attack, diabete, weight) %>%
  bind_cols(ps_weight = py$ps_weight) %>%
  group_by(diabete, heart_attack) %>%
  summarise(freq = sum(weight*ps_weight)) %>%
  mutate(
    prop = freq/sum(freq),
    freq_p = paste0(sprintf("%9.0f", freq),"(",
                    sprintf("%5.1f", prop*100),"%)")
  )%>%
  dplyr::select(-freq,-prop)
as_tibble_col(c("No","Yes"),column_name = "Heart Attack") %>%
  bind_cols(tab_weight[1:2,3]) %>%
  bind_cols(tab_weight[3:4,3]) %>%
  knitr::kable(format = "html", align = "lrr", caption = cap4,
                col.names = c("Heart Attack","Non-diabetes","Diabetes")) %>%
  kableExtra::kable_styling('striped', full_width = TRUE)
```
##### Table 5: Balance Checking

```{r py_balchech,echo=FALSE}
cap5 = "**Table 5:** Balance Checking Table before and after matching"
result_mean_after = do.call("rbind",py$result_mean_after)
result_sd_after = do.call("rbind",py$result_sd_after)
result_mean_before = do.call("rbind",py$result_mean_before)
result_sd_before = do.call("rbind",py$result_sd_before)
py$col %>%
  bind_cols(paste0(sprintf("%5.3f", result_mean_before[,1]),"(",
                       sprintf("%5.3f", result_sd_before[,1]),")")) %>%
  bind_cols(paste0(sprintf("%5.3f", result_mean_before[,2]),"(",
                       sprintf("%5.3f", result_sd_before[,2]),")")) %>%
  bind_cols(paste0(sprintf("%5.3f", result_mean_after[,1]),"(",
                       sprintf("%5.3f", result_sd_after[,1]),")")) %>%
  bind_cols(paste0(sprintf("%5.3f", result_mean_after[,2]),"(",
                       sprintf("%5.3f", result_sd_after[,2]),")")) %>%
  knitr::kable(format = "html", align = "lrrrr", caption = cap5,
               col.names = c("Covariate","Non-diabetes","Diabetes",
                             "Non-diabetes","Diabetes")) %>%
  kableExtra::kable_styling('striped', full_width = TRUE) %>%
  kableExtra::add_header_above(c(" " = 1, "Before Matching" = 2, 
                                 "After Matching" = 2))
```


#### Result Interpretation
Through **Table 1**, **Table 2** and **Table 4**, we can see that before matching/weighting, the rate of `heart attack` in diabetes patients is around 7 times larger than the non-diabetes patients. After matching/weighting, this rate decreases to only 2-3 times larger, which indicates that our matching/weighting significantly reduce the effect of the covariates. **Table 5** also shows similar result. Before matching, the `heart_attack` rate in `relative_heart_attack`, `age`, `bmi`, `blood_press`, `blood_press2`, `hyper_med`, `hbq_med`, `year_smoke` and `year_hyper` are significantly different between diabetes patients and non-diabetes patients. However, after matching, the rates in all corresponding covariates look similar, which is another evidence of the effect of propensity score matching. **Table 3** shows the t test result, which indicates that after matching, the `heart attack` rate in diabetes patients is still higher than the non-diabetes patients.

### R
```{r libraries, message = FALSE}
# libraries: ------------------------------------------------------------------
library(MatchIt)
library(survey)
library(tidyverse)
library(ggplot2)
library(tableone)

# data: -----------------------------------------------------------------------
nhanes = read_delim("./data/nhanes.csv", delim = ",")
nhanes = nhanes %>%
  mutate(
    diabete = as.factor(diabete),
    heart_attack = as.factor(heart_attack),
    gender = ifelse(gender == 2, 1, 0),
  )
```


#### I. Propensity score estimation
```{r p_score, warning = FALSE, message = FALSE}
## Logistic regression for treatment ~ pretreatment:
design_ps = svydesign( ids = ~1, weights = ~weight, data = nhanes )
ps_mod = svyglm(diabete ~ relative_heart_attack + gender + age + race + edu 
                + annual_income + bmi + smoke_life + phy_vigorous + phy_moderate 
                + blood_press + blood_press2 + hyper_med + hbq_med + high_chol 
                + meadial_access + cover_hc + health_diet + year_smoke + year_hyper,
                family = binomial(),
                design = design_ps)
#summary(ps_mod)

## Get the propensity score:
p_score = predict(ps_mod, type = "response")
```

<details>
<summary> Click to view `code for figure1`. </summary>
```{r propensity score distribution}
cap1 = "**figure 1.** *Propensity score distribution by Treated/Control Groups*"
ps = data.frame(
  p_score = ps_mod$fitted.values,
  Diabete = ifelse(ps_mod$model$diabete == 1, "Diabetes", "No Diabetes")
)

fig1 = ps %>%
  ggplot( aes(x = p_score) ) + 
  geom_histogram( aes(color = Diabete, fill = Diabete),
                      position = "identity", bins = 30, alpha = 0.3) +
  scale_color_manual(values = c("#00AFBB", "#E7B800")) +
  scale_fill_manual(values = c("#00AFBB", "#E7B800")) +
  xlab("Propensity Score") + 
  ylab("Frequency") +
  theme_bw()
```
</details>

```{r fig1, fig.cap=cap1}
cap1 = "**figure 1.** *Propensity score distribution by Treated/Control Groups*"
print(fig1)
```


#### II. Propensity score match:
```{r p_score matching}
nhanes_ps = nhanes %>% mutate( p_score = p_score)
match_mod = matchit(ps_mod$formula,
                    distance = 'logit',
                    method = "nearest", 
                    caliper = .2,
                    ratio = 1,
                    data = nhanes_ps,
                    replace = FALSE)
ps_match = match.data(match_mod)
#dim(ps_match)
```

#### III. Balance Checking:
```{r check balance}
var = c("relative_heart_attack", "gender", "age", "race", "edu", "annual_income",
        "bmi", "smoke_life", "phy_vigorous", "phy_moderate", "blood_press",
        "blood_press2", "hyper_med", "high_chol", "meadial_access", "cover_hc",
        "health_diet", "year_smoke", "year_hyper")
match_tab = CreateTableOne(vars=var, strata="diabete", data=ps_match, test=FALSE)
print(match_tab, smd = TRUE)  
```

#### IV. Comparison between pre_match data and matched data.
##### **Table 1: **
<details>
<summary> Click to view `code for Table1`. </summary>
```{r tab1_}
tab_pre_mt = nhanes %>%
  group_by(diabete, heart_attack) %>%
  summarize(n = sum(weight), .groups = "drop_last") %>%
  mutate(
    prop = 100*(n / sum(n))
  ) %>%
  transmute(
    `Heart Attack` = ifelse(heart_attack == 1, "YES", "NO"),
    Diabetes = ifelse(diabete == 1, "Diabetes", "NoDiabetes"),
    prop = sprintf('%10.0f (%4.2f%%)', n, prop)
  ) %>%
  pivot_wider(
    id_cols = `Heart Attack`,
    names_from = Diabetes,
    values_from = prop
  ) %>%
  knitr::kable(format = 'html') %>%
  kableExtra::kable_styling("striped", full_width = TRUE) %>%
  kableExtra::add_header_above(
    header = c("Proportion of Heat Attack with Pre-matched Group" = 3)
  )
```
</details>

```{r table1, echo = FALSE}
tab_pre_mt
```
##### **Table 2: **
<details>
<summary> Click to view `code for Table2`. </summary>
```{r tab2_}
tab_mt = ps_match %>%
  group_by(diabete, heart_attack) %>%
  summarize(n = sum(weight), .groups = "drop_last") %>%
  mutate(
    prop = 100*(n / sum(n))
  ) %>%
  transmute(
    `Heart Attack` = ifelse(heart_attack == 1, "YES", "NO"),
    Diabetes = ifelse(diabete == 1, "Diabetes", "NoDiabetes"),
    prop = sprintf('%10.0f (%4.2f%%)', n, prop)
  ) %>%
  pivot_wider(
    id_cols = `Heart Attack`,
    names_from = Diabetes,
    values_from = prop
  ) %>%
  knitr::kable(format = 'html') %>%
  kableExtra::kable_styling("striped", full_width = TRUE) %>%
  kableExtra::add_header_above(
    header = c("Proportion of Heat Attack with Matched Group" = 3)
  )
```
</details>


```{r table2, echo = FALSE}
tab_mt
```


#### V. Inverse propensity score weighting:
##### **Table 3: **
<details>
<summary> Click to view `code for Table3`. </summary>
```{r ipw}
invert = nhanes_ps %>%
  select(diabete, heart_attack, weight, p_score) %>%
  mutate(
    inverse_wt = ifelse(diabete == 1, 1/p_score, 1/(1-p_score)),
    new_wt = weight * inverse_wt
  ) %>% 
  group_by(diabete, heart_attack) %>%
  summarize(n = sum(new_wt), .groups = "drop_last") %>%
  mutate(
    prop = 100*(n / sum(n))
  ) %>%
  transmute(
    `Heart Attack` = ifelse(heart_attack == 1, "YES", "NO"),
    Diabetes = ifelse(diabete == 1, "Diabetes", "NoDiabetes"),
    prop = sprintf('%10.0f (%4.2f%%)', n, prop)
  ) %>%
  pivot_wider(
    id_cols = `Heart Attack`,
    names_from = Diabetes,
    values_from = prop
  ) %>%
  knitr::kable(format = 'html') %>%
  kableExtra::kable_styling("striped", full_width = TRUE) %>%
  kableExtra::add_header_above(
    header = c("Proportion of Heat Attack with Inverse Propensity Weight" = 3)
  )
```
</details>

```{r table3, echo = FALSE}
invert
```



### SAS

<details>
 <summary> `GroupProject_SAS_Hongfan.sas` </summary>
```{r GroupProject_SAS_Hongfan.sas, comment=""}
readLines("./SAS/GroupProject_SAS_Hongfan.sas")
```
</details>

#### Code of makeing table

```{r make tables, message=FALSE}
beforematch = read_delim("./SAS/output/freq_table.csv", delim = ',')
aftermatch = read_delim("./SAS/output/freq_table_merge.csv", delim = ',')
inverseweight = read_delim("./SAS/output/ps_match_inverse_table.csv", delim = ',')
tab = function(df, header = c("Proportion" = 3), cap = "hello"){
  df %>%
  mutate(
    `Heart Attack` = ifelse(heart_attack == 1, "YES", "NO"),
    diabetes = ifelse(diabetes == 1, "Diabetes", "Non-Diabetes")
    ) %>%
  group_by(diabetes) %>%
  mutate(pct = COUNT / sum(COUNT)) %>%
  mutate(COUNT_PCT = sprintf('%.0f (%.1f%s)', COUNT, pct * 100, "%")) %>%
  select(`Heart Attack`, diabetes, COUNT_PCT) %>%
  pivot_wider(id_cols = `Heart Attack`,
               names_from = 'diabetes', 
               values_from = 'COUNT_PCT') %>%
  knitr::kable(format = 'html', caption = cap) %>%
  kableExtra::kable_styling("striped", full_width = TRUE) %>%
  kableExtra::add_header_above(header)
}
```

#### Before Match

```{r table_1_sas}
cap = paste0(
"**Table 1.** Proportion of Heat Attack with Pre-matched Group"
)
tab(beforematch,
    header = c("Proportion of Heat Attack with Pre-matched Group" = 3),
    cap = cap
    )
```

#### After Match

```{r table_2_sas}
cap = paste0(
"**Table 2.** Proportion of Heat Attack with Matched Group"
)
tab(aftermatch,
    header = c("Proportion of Heat Attack with Matched Group" = 3),
    cap = cap
    )
```

#### Using Iverse Propensity Weight

```{r table_3_sas}
cap = paste0(
"**Table 3.** Proportion of Heat Attack with Inverse Propensity Weight"
)
tab(inverseweight, 
    header = c("Proportion of Heat Attack with Inverse Propensity Weight " = 3), 
    cap = cap
    )
```


### STATA
```{stata s1, collectcode=TRUE}
import delimited "./data/nhanes.csv", encoding(ISO-8859-1)
```
#### Initial Data Balance:
This will allow us to determine, which covariates will be useful when calculating the propensity score. 
* To-Do 
  + Create Confidence Intervals for all of the variables in order to know which to choose in our final model
  + create a standardized balance table and compare the means 
```{stata s2, collectcode=TRUE}
logit heart_attack relative_heart_attack gender age race edu annual_income weight bmi diabete smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper
 
ttest diabete, by(heart_attack)
```

#### I. Propensity score estimation:

```{stata s3, collectcode=TRUE, results="hide"}
pscore diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper, pscore(pc_pscore) blockid(pc_block) detail
psgraph, treated(diabete)pscore(pc_pscore)
```

#### II. Propensity score matching/weighting:
* To-Do
  + create graphics 
  + for matching, I will create a line graph and juxtapose the untreated vs. treated 
  + for weighting, I will create two density graphs to compare 

##### Matching 

```{stata s4, collectcode=TRUE}
qui psmatch2 diabete, kernel outcome(heart_attack) pscore(pc_pscore)
```

##### Inverse Propensity Score Weighting 
```{stata s5, collectcode=TRUE}
qui dr heart_attack diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper, genvars
egen sumofweights = total(iptwt)
gen norm_weights = iptwt/sumofweights
```

#### III. Balance Checking:
* To-Do 
  + I will also a linear regression estimation using the teffects ra function 
  
#### Matched Data Balance 
```{stata s6, collectcode=TRUE}
psmatch2 diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper, out(heart_attack)
 
reg heart_attack relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper diabete [fweight = _weight]
 
teffects ipw (heart_attack) (diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper)
```

#### Inverse Weighting Balance

```{stata s7, collectcode=TRUE}
pbalchk diabete heart_attack diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper, wt(norm_weights)
 
teffects ipwra (heart_attack relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper) (diabete relative_heart_attack gender age race edu annual_income weight bmi smoke_life phy_vigorous phy_moderate blood_press blood_press2 hyper_med hbq_med high_chol meadial_access cover_hc health_diet year_smoke year_hyper)
```

#### IV. Comparison between pre_match data and matched data.
* To-Do  
  + Create Graphs comparing pre-match data and match data 
  + Create graphs comparing pre-weighted data to weighted data 
  + standardized tables for both matched and weighted data to compare to initial data set


